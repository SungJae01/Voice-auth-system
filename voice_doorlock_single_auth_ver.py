# 1ì°¨, 2ì°¨ ì¸ì¦ê³¼ì • í†µí•©

import sys
import os
import random
import torch
import torchaudio
import librosa
import sounddevice as sd
import soundfile as sf
import numpy as np

#PyQt5 ë¼ì´ë¸ŒëŸ¬ë¦¬
from PyQt5.QtWidgets import (
    QApplication, QWidget, QVBoxLayout, QPushButton, QLabel,
    QMessageBox, QInputDialog, QDialog, QHBoxLayout
)
from PyQt5.QtCore import Qt, QTimer, QThread, pyqtSignal, QUrl, QSize
from PyQt5.QtMultimedia import QMediaPlayer, QMediaContent
from PyQt5.QtGui import QMovie
from transformers import Wav2Vec2Model, Wav2Vec2Processor
from speechbrain.pretrained import SpeakerRecognition
import whisper
from sentence_transformers import SentenceTransformer

#nodeMCU WiFi í†µì‹  ë¼ì´ë¸ŒëŸ¬ë¦¬
import socket, time, logging


# ========== ì„¤ì • ==========
SAMPLE_RATE = 16000
RECORD_DURATION = 10
RECORD_SECONDS_LOGIN = 10
PROFILES_DIR = "profiles"
SIMILARITY_THRESHOLD = 0.6
ALPHA = 0.5
os.makedirs(PROFILES_DIR, exist_ok=True)

# ===== ë¡œê¹… ì„¤ì • =====
LOG_DIR = "logs"
os.makedirs(LOG_DIR, exist_ok=True)
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(os.path.join(LOG_DIR, "app.log"), encoding="utf-8"),
        logging.StreamHandler()
    ]
)

def _excepthook(exc_type, exc, tb):
    logging.error("Uncaught exception", exc_info=(exc_type, exc, tb))

import sys as _sys
_sys.excepthook = _excepthook

# AP ëª¨ë“œë¼ë©´ ê¸°ë³¸ IP, STA ëª¨ë“œë¼ë©´ nodeMCU ì‹œë¦¬ì–¼ ëª¨ë‹ˆí„°ì— ëœ¬ IPë¡œ ë°”ê¾¸ì„¸ìš”.
NODEMCU_HOST = "192.168.123.110"   # ë˜ëŠ” ì˜ˆ: "192.168.0.37"
NODEMCU_PORT = 7777

# ========== ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ==========
# í™”ì ì‹ë³„ ecapa_model ë¡œë”©
ecapa_model = SpeakerRecognition.from_hparams(
    source="speechbrain/spkrec-ecapa-voxceleb",
    savedir="ecapa_model"
)
# ìŒì„± Pitch ëª¨ë¸ ë¡œë”©
wav2vec_model = Wav2Vec2Model.from_pretrained("facebook/wav2vec2-base")
wav2vec_processor = Wav2Vec2Processor.from_pretrained("facebook/wav2vec2-base")
wav2vec_model.eval()

# í…ìŠ¤íŠ¸ - í…ìŠ¤íŠ¸ ì˜ë¯¸ ìœ ì‚¬ë„ ë¹„êµ ëª¨ë¸ ë¡œë”©
sbert = SentenceTransformer("all-MiniLM-L6-v2")

# WhisperëŠ” MPS ë§ê³  CPU/CUDAë§Œ ì‚¬ìš© (MPSì—ì„œ sparse ì—ëŸ¬ ë°©ì§€)
WHISPER_DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
USE_FP16 = torch.cuda.is_available()  # CUDAì¼ ë•Œë§Œ fp16

whisper_model = whisper.load_model("small", device=WHISPER_DEVICE)

# Silero VAD ëª¨ë¸ ë¡œë”©
vad_model, utils = torch.hub.load(
    repo_or_dir='snakers4/silero-vad',
    model='silero_vad',
    trust_repo=True
)
(get_speech_timestamps, _, _, _, collect_chunks) = utils  # save_audio/read_audio/VADIterator ë¯¸ì‚¬ìš©

# ========== ì„ë² ë”©/ë¹„êµ í•¨ìˆ˜ ==========
def extract_pitch(y, sr, target_len=512):
    pitches, magnitudes = librosa.piptrack(y=y, sr=sr)
    vals = [pitches[magnitudes[:, t].argmax(), t] for t in range(pitches.shape[1])]
    vals = np.nan_to_num(vals)
    vals = librosa.util.fix_length(vals, size=target_len)
    return torch.tensor(vals).float().unsqueeze(0)

def get_ecapa_embedding(path):
    wav, sr = torchaudio.load(path)
    wav = torch.mean(wav, dim=0, keepdim=True)
    if sr != SAMPLE_RATE:
        wav = torchaudio.transforms.Resample(sr, SAMPLE_RATE)(wav)
    emb = ecapa_model.encode_batch(wav).squeeze(0)
    return emb.unsqueeze(0)

def get_wav2vec_pitch_embedding(path):
    y, sr = librosa.load(path, sr=SAMPLE_RATE)
    inputs = wav2vec_processor(y, sampling_rate=sr, return_tensors="pt").input_values
    with torch.no_grad():
        out = wav2vec_model(inputs)
    wav_emb = torch.mean(out.last_hidden_state, dim=1)
    pitch_emb = torch.mean(extract_pitch(y, sr), dim=1, keepdim=True) / 300.0
    return torch.cat((wav_emb, pitch_emb), dim=1)

def cosine_similarity(a, b):
    return torch.nn.functional.cosine_similarity(a, b).mean().item()

# ecapa ìœ ì‚¬ë„ ì ìˆ˜ + wav2vec_pitch ìœ ì‚¬ë„ ì ìˆ˜ (alphaê°’ìœ¼ë¡œ ê°€ì¤‘ì¹˜ ì¡°ì ˆ)
def compare_with_ensemble(emb1_dir, test_audio, alpha=ALPHA):
    try:
        emb1_ecapa = torch.load(os.path.join(emb1_dir, "ecapa.pt")).unsqueeze(0)
        emb1_wav = torch.load(os.path.join(emb1_dir, "wav2vec.pt")).unsqueeze(0)
    except (FileNotFoundError, OSError, RuntimeError) as e:
        logging.warning("Embedding load failed for %s: %s", emb1_dir, e)
        return -1e9  # ìœ íš¨í•˜ì§€ ì•Šì€ í”„ë¡œí•„ë¡œ ê°„ì£¼

    emb2_ecapa = get_ecapa_embedding(test_audio)
    emb2_wav = get_wav2vec_pitch_embedding(test_audio)

    sim_ecapa = cosine_similarity(emb1_ecapa, emb2_ecapa)
    sim_wav = cosine_similarity(emb1_wav, emb2_wav)
    return alpha * sim_wav + (1 - alpha) * sim_ecapa

# ì˜ë¯¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ì—¬ true, false ë°˜í™˜ (0.8 ì´ìƒ = true)
def semantic_similarity(a: str, b: str, threshold: float = 0.8) -> bool:
    embs = sbert.encode([a, b], convert_to_tensor=True)
    sim = torch.nn.functional.cosine_similarity(embs[0], embs[1], dim=0).item()
    print(f"[ì˜ë¯¸ìœ ì‚¬ë„] cos={sim:.3f}")
    return sim >= threshold


def send_nodemcu(cmd: str, host=NODEMCU_HOST, port=NODEMCU_PORT, timeout=1.5, read_reply=False, retries=3, backoff=0.3):
    """
    NodeMCU TCP ì„œë²„(7777)ì— í•œ ì¤„ ëª…ë ¹ì„ ë³´ëƒ…ë‹ˆë‹¤. ì˜ˆì™¸/íƒ€ì„ì•„ì›ƒì— ëŒ€í•´ ì¬ì‹œë„(backoff)í•˜ë©°,
    read_reply=Trueë©´ ì²« ë¼ì¸ì„ ë°˜í™˜(ì—†ìœ¼ë©´ ê³µë°± ë¬¸ìì—´).
    """
    last_err = None
    for attempt in range(1, retries + 1):
        try:
            with socket.create_connection((host, port), timeout=timeout) as s:
                s.sendall((cmd.strip() + "\n").encode("utf-8"))
                if read_reply:
                    s.settimeout(timeout)
                    try:
                        data = s.recv(1024).decode("utf-8", errors="ignore").strip()
                        return data
                    except socket.timeout:
                        logging.warning("send_nodemcu reply timeout: %s", cmd)
                        return ""
                return ""
        except (ConnectionRefusedError, TimeoutError, OSError, socket.error) as e:
            last_err = e
            logging.warning("send_nodemcu attempt %d/%d failed: %s", attempt, retries, e)
            time.sleep(backoff * attempt)
    raise RuntimeError(f"{last_err}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ í†µí•© ì¸ì¦ ì›Œì»¤ (ë…¹ìŒ + STT + ì˜ë¯¸ìœ ì‚¬ë„ + í™”ìê²€ì¦ + nodeMCU ì „ì†¡) â”€â”€â”€â”€â”€â”€â”€â”€â”€
class UnifiedAuthWorker(QThread):
    finished = pyqtSignal(bool, str, str)   # success, user(best match or ""), message
    recording_done = pyqtSignal()           # ğŸ”” "ë…¹ìŒ ì¢…ë£Œ" ì•Œë¦¼ ì‹ í˜¸ ì¶”ê°€

    def __init__(self, expected_sentence: str, profiles: list, attempts_left: int, parent=None):
        super().__init__(parent)
        self.expected_sentence = expected_sentence
        self.profiles = profiles
        self.attempts_left = attempts_left

    def run(self):
        # 1) ë…¹ìŒ
        try:
            ok = record_until_silence("auth.wav", RECORD_SECONDS_LOGIN)
        except Exception as e:
            logging.exception("UnifiedAuthWorker record error: %s", e)
            self.finished.emit(False, "", "ë…¹ìŒ ì‹¤íŒ¨")
            return
        if not ok:
            self.finished.emit(False, "", "ìŒì„± ë¯¸ê°ì§€")
            return

        # ğŸ”” ë…¹ìŒì´ "ì •ìƒ ì¢…ë£Œ"ë˜ë©´ ì¦‰ì‹œ UIì— ì•Œë¦¼ â†’ Find people.gifë¡œ ì „í™˜
        self.recording_done.emit()

        # 2) Whisper STT
        try:
            result = whisper_model.transcribe(
                "auth.wav",
                language="ko",
                temperature=0.0,
                beam_size=1, best_of=1,
                condition_on_previous_text=False,
                fp16=USE_FP16,
                initial_prompt="ìŠ¤ë§ˆíŠ¸ ë„ì–´ë½, ì¸ì¦, ê´‘í™”ë¬¸, ë‚ ì”¨"
            )
            spoken = result["text"].strip().lower()
        except Exception as e:
            logging.exception("Whisper error: %s", e)
            self.finished.emit(False, "", "ìŒì„± ì¸ì‹ ì‹¤íŒ¨")
            return

        # 3) ì˜ë¯¸ ìœ ì‚¬ë„
        try:
            sem_ok = semantic_similarity(self.expected_sentence.lower(), spoken)
        except Exception as e:
            logging.exception("Semantic compare error: %s", e)
            sem_ok = False

        # 4) í™”ì ìœ ì‚¬ë„(ë“±ë¡ í”„ë¡œí•„ ì¤‘ ìµœê³ ê°’)
        best_match, best_score = None, -1e9
        try:
            for p in self.profiles:
                profile_dir = os.path.join(PROFILES_DIR, p)
                score = compare_with_ensemble(profile_dir, "auth.wav", alpha=ALPHA)
                print(f"[ìœ ì‚¬ë„] {p}: {score:.4f}")
                if score > best_score:
                    best_score = score
                    best_match = p
            spk_ok = (best_score >= SIMILARITY_THRESHOLD)
        except Exception as e:
            logging.exception("Embedding compare error: %s", e)
            self.finished.emit(False, "", "í”„ë¡œí•„ ë¹„êµ ì‹¤íŒ¨")
            return

        success = sem_ok and spk_ok
        if success:
            msg = f"{best_match}ë‹˜ ì•ˆë…•í•˜ì„¸ìš”! ë„ì–´ë½ì´ ì—´ë ¸ìŠµë‹ˆë‹¤"
            self.finished.emit(True, best_match, msg)
        else:
            if not sem_ok and not spk_ok:
                reason = "ë¬¸ì¥ ë¶ˆì¼ì¹˜ + ë“±ë¡ë˜ì§€ ì•Šì€ ìŒì„±\n"
            elif not sem_ok:
                reason = "ë¬¸ì¥ ì˜ë¯¸ ë¶ˆì¼ì¹˜\n"
            else:
                reason = "ë“±ë¡ë˜ì§€ ì•Šì€ ìŒì„±"
            left = max(0, self.attempts_left - 1)
            msg = f"ì¸ì¦ ì‹¤íŒ¨: {reason} (ë‚¨ì€ ì‹œë„ {left}íšŒ)"
            self.finished.emit(False, best_match or "", msg)

class NodeMCUWorker(QThread):
    error = pyqtSignal(str)

    def __init__(self, open_ms=7000, polls=8, interval=0.4, parent=None):
        super().__init__(parent)
        self.open_ms = open_ms
        self.polls = polls
        self.interval = interval
        self._stop = False

    def stop(self):
        self._stop = True

    def run(self):
        try:
            send_nodemcu(f"OPEN {self.open_ms}")
            for _ in range(self.polls):
                if self._stop:
                    break
                send_nodemcu("STATUS")
                time.sleep(self.interval)
        except Exception as e:
            self.error.emit(str(e))


# ========== ë…¹ìŒ ë° VAD í•¨ìˆ˜ ==========
def record_until_silence(path,
                        max_duration,
                        block_duration=0.5,
                        silence_blocks_thresh=2):
    """
    â€¢ with InputStream: ë¸”ë¡ ì¢…ë£Œ ì‹œì ì— ìŠ¤íŠ¸ë¦¼ì´ ìë™ close â†’ semaphore ëˆ„ìˆ˜ ë°©ì§€
    â€¢ block_duration ì´ˆì”© ì½ì–´ì„œ VAD ê²€ì‚¬
    â€¢ speech_started í›„ silence_blocks_thresh ì—°ì† ë¬´ìŒ ì‹œ ë…¹ìŒ ì¢…ë£Œ
    """
    blocks = []
    speech_started = False
    silence_blocks = 0
    max_blocks = int(max_duration / block_duration)

    try:
        with sd.InputStream(samplerate=SAMPLE_RATE, channels=1, dtype='float32') as stream:
            for _ in range(max_blocks):
                audio, _ = stream.read(int(SAMPLE_RATE * block_duration))
                if audio is None or len(audio) == 0:
                    continue
                blocks.append(audio)

                wav = torch.from_numpy(audio.squeeze()).float()
                ts = get_speech_timestamps(wav, vad_model, sampling_rate=SAMPLE_RATE)
                if ts:
                    speech_started = True
                    silence_blocks = 0
                elif speech_started:
                    silence_blocks += 1

                if speech_started and silence_blocks >= silence_blocks_thresh:
                    break
    except Exception as e:
        logging.exception("Audio input error: %s", e)
        return False

    if not blocks:
        return False

    try:
        full = np.concatenate(blocks, axis=0)
        wav_full = torch.from_numpy(full.squeeze()).float()
        speech_ts = get_speech_timestamps(wav_full, vad_model, sampling_rate=SAMPLE_RATE)
        if not speech_ts:
            return False
        voiced = collect_chunks(speech_ts, wav_full)
        sf.write(path, voiced.numpy(), SAMPLE_RATE)
        return True
    except Exception as e:
        logging.exception("Post-record/VAD error: %s", e)
        return False


# ========== í”„ë¡œí•„ ìƒì„± ë…¹ìŒ ì•ˆë‚´ ë‹¤ì´ì–¼ë¡œê·¸ ==========
class RecordingDialog(QDialog):
    def __init__(self, sentence, record_func, path, duration):
        super().__init__()
        self.setWindowTitle("ğŸ™ ë…¹ìŒ ì•ˆë‚´")
        self.setFixedSize(400, 200)
        self.record_func = record_func
        self.path = path
        self.duration = duration

        lay = QVBoxLayout()
        lbl = QLabel(f"ğŸ“¢ ë‹¤ìŒ ë¬¸ì¥ì„ ë˜ë°•ë˜ë°• ì½ì–´ì£¼ì„¸ìš”:\n\nã€ {sentence} ã€")
        lbl.setWordWrap(True)
        lay.addWidget(lbl)

        btn = QPushButton("ğŸ¤ ë…¹ìŒ ì‹œì‘")
        btn.clicked.connect(self._do_record)
        lay.addWidget(btn)

        self.setLayout(lay)

    def _do_record(self):
        self.record_func(self.path, self.duration)
        self.accept()


# ========== ë©”ì¸ UI ==========
class SmartDoorlockUI(QWidget):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("ğŸ” ìŠ¤ë§ˆíŠ¸ ë„ì–´ë½ ì‹œë®¬ë ˆì´í„°")
        self.setGeometry(1800, 0, 500, 1285)    # ì‹¤ì œ ì†Œí˜• LCD í™”ë©´ ë¹„ìœ¨ê³¼ ìœ ì‚¬í•˜ê²Œ
        self.setStyleSheet("background-color: white;")
        self.auth_fail_count = 0    # ì‹¤íŒ¨ íšŸìˆ˜ ì´ˆê¸°í™”
        self.attempts_left = 3      # í†µí•© ì¸ì¦ ì´ ì‹œë„ íšŸìˆ˜

        # â”€â”€ ë©”ì¸ ë ˆì´ì•„ì›ƒ â”€â”€
        main_lay = QVBoxLayout(self)
        main_lay.setContentsMargins(0,0,0,0)

        # â”€â”€ ì• ë‹ˆë©”ì´ì…˜ ë¼ë²¨ & ë…¹ìŒì¤‘ ë ˆì´ë¸” ì¤€ë¹„ â”€â”€
        self.label = QLabel(self)
        self.label.setFixedSize(500, 500)
        self.label.setAlignment(Qt.AlignCenter)
        self.movie = QMovie("gif/MainScene.gif")
        self.label.setFixedHeight(500)
        # ìµœì´ˆì—” ì¬ìƒí•˜ì§€ ì•Šê³  ì²« í”„ë ˆì„ë§Œ
        self.movie.jumpToFrame(0)
        self.label.setPixmap(self.movie.currentPixmap())
        main_lay.addWidget(self.label)

        # â”€â”€ í†µí•© ì¸ì¦ ë¬¸ì¥ í‘œì‹œìš© ë ˆì´ë¸” â”€â”€
        self.challenge_label = QLabel("", self)
        self.challenge_label.setAlignment(Qt.AlignCenter)
        self.challenge_label.setStyleSheet("color: #bbbbbf; font-size: 23px;")
        self.challenge_label.setFixedHeight(100)
        self.challenge_label.hide()
        main_lay.addWidget(self.challenge_label)

        # â”€â”€ ë¯¸ë””ì–´ í”Œë ˆì´ì–´ ì¤€ë¹„ â”€â”€
        self.player = QMediaPlayer(self)

        # â”€â”€ ìƒíƒœ ë©”ì‹œì§€ ë ˆì´ë¸” ì¶”ê°€ â”€â”€
        self.status_label = QLabel("", self)
        self.status_label.setAlignment(Qt.AlignCenter)
        self.status_label.setStyleSheet("""
            color: #bbbbbf;
            font-size: 23px;
            padding: 8px;
        """)
        self.status_label.setFixedHeight(100)
        main_lay.addWidget(self.status_label)

        # â”€â”€ â€œë…¹ìŒì¤‘â€ í…ìŠ¤íŠ¸ ë ˆì´ë¸” â”€â”€
        self.recording_label = QLabel("ë…¹ìŒì¤‘â€¦", self)
        self.recording_label.setAlignment(Qt.AlignCenter)
        self.recording_label.setStyleSheet("color: #bbbbbf; font-size: 23px;")
        self.recording_label.setFixedHeight(60)
        self.recording_label.hide()               # ì´ˆê¸°ì—ëŠ” ìˆ¨ê¹€
        main_lay.addWidget(self.recording_label)

        # â”€â”€ ìœ„ì ¯ë“¤ ì‚¬ì´ì˜ ë‚¨ëŠ” ê³µê°„ì„ ì „ë¶€ ì°¨ì§€í•  ìŠ¤íŠ¸ë ˆì¹˜ ì¶”ê°€ â”€â”€
        main_lay.addStretch()

        # â”€â”€ ë²„íŠ¼ ë ˆì´ì•„ì›ƒ â”€â”€
        hbtn = QHBoxLayout()
        self.detect_btn = QPushButton("ğŸš¶ ì‚¬ìš©ì ì ‘ê·¼ ê°ì§€"); 
        self.detect_btn.clicked.connect(self.on_user_detected)
        self.detect_btn.setStyleSheet("""
            QPushButton {
                background-color: #3498db;
                color: white;
                border: none;
                padding: 8px 16px;
                border-radius: 4px;
            }
        """)
        self.create_btn = QPushButton("â• í”„ë¡œí•„ ìƒì„±");     
        self.create_btn.clicked.connect(self.create_profile)
        self.create_btn.setStyleSheet("""
            QPushButton {
                background-color: #3498db;
                color: white;
                border: none;
                padding: 8px 16px;
                border-radius: 4px;
            }
        """)
        hbtn.addWidget(self.detect_btn); hbtn.addWidget(self.create_btn)
        main_lay.addLayout(hbtn)

        self.profiles = []
        self.load_profiles()

        self.lockdown_timer = QTimer(self)
        self.lockdown_timer.setInterval(1000)  # 1ì´ˆ
        self.lockdown_timer.timeout.connect(self._tick_lockdown)
        self.lockdown_remaining = 0

    # í”„ë¡œí•„ ìƒì„± (ecapa ì„ë² ë”© íŒŒì¼, wav2vec ì„ë² ë”© íŒŒì¼, ìŒì„± ë…¹ìŒë³¸ 5ê°œ ìƒì„±í•˜ì—¬ í”„ë¡œí•„ì— ì €ì¥)
    def create_profile(self):
        name, ok = QInputDialog.getText(self, "í”„ë¡œí•„ ìƒì„±", "ì‚¬ìš©ì ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”:")
        if not ok or not name.strip():
            return
        name = name.strip()
        profile_dir = os.path.join(PROFILES_DIR, name)
        if os.path.exists(profile_dir):
            QMessageBox.warning(self, "ì¤‘ë³µ", "ì´ë¯¸ ì¡´ì¬í•˜ëŠ” í”„ë¡œí•„ì…ë‹ˆë‹¤.")
            return
        os.makedirs(profile_dir, exist_ok=True)

        sentences = [
            "ìŒì„±ìœ¼ë¡œ ë¬¸ì„ ì—´ê² ìŠµë‹ˆë‹¤. ì§€ê¸ˆë¶€í„° ì¸ì¦ì„ ì‹œì‘í•©ë‹ˆë‹¤.",
            "ì´ ë¬¸ì¥ì„ ì •í™•íˆ ë§í•˜ë©´ ì ê¸ˆì¥ì¹˜ê°€ í•´ì œë©ë‹ˆë‹¤.",
            "ì§€ê¸ˆ ë“¤ë¦¬ëŠ” ì´ ëª©ì†Œë¦¬ëŠ” ì €ë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë³´ì•ˆ ì—´ì‡ ì…ë‹ˆë‹¤.",
            "ìŠ¤ë§ˆíŠ¸ ë„ì–´ ì‹œìŠ¤í…œì„ í†µí•´ ì§‘ì— ì•ˆì „í•˜ê²Œ ë“¤ì–´ê°€ê³  ì‹¶ìŠµë‹ˆë‹¤.",
            "ì´ì œ ì œ ìŒì„±ìœ¼ë¡œ ë¬¸ì„ ì—´ ìˆ˜ ìˆëŠ” ì‹œëŒ€ê°€ ì™”ìŠµë‹ˆë‹¤. ì—´ì–´ì£¼ì„¸ìš”."
        ]

        ecapa_embs, wav_embs = [], []
        for i, sentence in enumerate(sentences):
            rec_path = os.path.join(profile_dir, f"rec{i+1}.wav")
            dialog = RecordingDialog(
                sentence,
                record_until_silence,
                rec_path,
                RECORD_DURATION
            )
            dialog.exec_()

            ecapa_embs.append(get_ecapa_embedding(rec_path).squeeze(0))
            wav_embs.append(get_wav2vec_pitch_embedding(rec_path).squeeze(0))

        # í‰ê·  ì„ë² ë”© ì €ì¥
        torch.save(torch.stack(ecapa_embs).mean(0), os.path.join(profile_dir, "ecapa.pt"))
        torch.save(torch.stack(wav_embs).mean(0),  os.path.join(profile_dir, "wav2vec.pt"))

        QMessageBox.information(self, "ì™„ë£Œ", "í”„ë¡œí•„ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        self.load_profiles()

    def load_profiles(self):
        try:
            self.profiles = [d for d in os.listdir(PROFILES_DIR)
                            if os.path.isdir(os.path.join(PROFILES_DIR, d))]
        except Exception as e:
            logging.exception("load_profiles error: %s", e)
            self.profiles = []

    def on_recording_done(self):
        """ë…¹ìŒ ì¢…ë£Œ ì§í›„: 'ë…¹ìŒì¤‘â€¦' ê°ì¶”ê³  Find people.gifë¡œ ì „í™˜"""
        self.recording_label.hide()
        self.movie = QMovie("gif/Find people.gif")
        self.label.setMovie(self.movie)
        self.movie.setSpeed(75)
        self.movie.start()

    def clear_status(self, delay=4000):
        """delay(ms) ë’¤ì— ë©”ì‹œì§€ ì§€ìš°ê¸°."""
        QTimer.singleShot(delay, lambda: self.status_label.setText(""))

    # ì‚¬ìš©ì ê°ì§€ (ë„ì–´ë½ ì¸ì¦ ê³¼ì • ì‹œì‘)
    def on_user_detected(self):
        # 1) MP3 ì¬ìƒ â”€â”€
        mp3_path = os.path.abspath("mp3/Apple Intelligence Sound Effect.mp3")  # ì¬ìƒí•  íŒŒì¼ ê²½ë¡œ
        url = QUrl.fromLocalFile(mp3_path)
        media = QMediaContent(url)
        self.player.setMedia(media)
        self.player.play()

        # 2) ëœë¤ ë¬¸ì¥ ì¤€ë¹„ (ì´ë¯¸ ìˆë‹¤ë©´ ìƒëµ)
        sentence = random.choice([
            "ì„œìš¸ì˜ ì¤‘ì‹¬ì€ ê´‘í™”ë¬¸ì…ë‹ˆë‹¤.",
            "ì˜¤ëŠ˜ë„ ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”.",
            "ë´„ì—ëŠ” ê½ƒì´ í”¼ê³  ìƒˆê°€ ë‚ ì•„ìš”."
        ])
        self.current_sentence = sentence

        # âœ… ë¬¸ì¥ ë¼ë²¨ì— í‘œì‹œ + ë³´ì´ê¸°
        self.challenge_label.setText(f"ì•„ë˜ ë¬¸ì¥ì„ ì½ì–´ì£¼ì„¸ìš”!\n\nã€Œ{self.current_sentence}ã€")
        self.challenge_label.show() 

        # 3) ë…¹ìŒ "ì¤‘"ì—ëŠ” MainScene.gif ì¬ìƒ
        self.movie = QMovie("gif/MainScene.gif")
        self.label.setMovie(self.movie)
        self.movie.setSpeed(75)
        self.movie.start()
        self.recording_label.setText("ë…¹ìŒì¤‘â€¦")
        self.recording_label.show()
        self.detect_btn.setEnabled(False)

        # 4) í†µí•© ì¸ì¦ ì›Œì»¤ ì‹œì‘ + ì‹ í˜¸ ì—°ê²°
        self.auth_worker = UnifiedAuthWorker(
            expected_sentence=self.current_sentence,
            profiles=self.profiles,
            attempts_left=self.attempts_left  # ë˜ëŠ” self.attempts_left
        )
        self.auth_worker.recording_done.connect(self.on_recording_done)  # ğŸ”— ì—¬ê¸°!
        self.auth_worker.finished.connect(self.on_auth_finished)  # ê¸°ì¡´ ì™„ë£Œ ìŠ¬ë¡¯
        self.auth_worker.start()

    # ì¸ì¦ ê³¼ì • ì¢…ë£Œ ì‹œì 
    def on_auth_finished(self, success: bool, user: str, message: str):
        # ë¬¸ì¥ ìˆ¨ê¹€ & ë…¹ìŒì¤‘ ìˆ¨ê¹€
        self.challenge_label.hide()
        self.recording_label.hide()

        # ê²°ê³¼ ì• ë‹ˆë©”ì´ì…˜ + ì‚¬ìš´ë“œ
        if success:
            movie = QMovie("gif/Success.gif")
            self.label.setMovie(movie)
            movie.setSpeed(75)
            movie.start()
            # ì„±ê³µ ì‹œ NodeMCU ì œì–´(ë°±ê·¸ë¼ìš´ë“œ)
            self.nodemcu_worker = NodeMCUWorker(open_ms=7000, polls=8, interval=0.4)
            self.nodemcu_worker.error.connect(self._on_nodemcu_error)
            self.nodemcu_worker.start()
            # 5ì´ˆ í›„ ë©”ì¸ í™”ë©´ìœ¼ë¡œ ë¦¬ì…‹
            QTimer.singleShot(5000, self.reset_to_main_scene)
            self.attempts_left = 3  # ì„±ê³µ ì‹œ ì‹œë„íšŸìˆ˜ ë¦¬ì…‹
        else:
            # ì˜¤ë¥˜ ì‚¬ìš´ë“œ
            mp3_path = os.path.abspath("mp3/Mac Error Sound Effect.mp3")
            url = QUrl.fromLocalFile(mp3_path)
            media = QMediaContent(url)
            self.player.setMedia(media)
            self.player.play()

            movie = QMovie("gif/Error animation.gif")
            self.label.setMovie(movie)
            movie.setSpeed(75)
            movie.start()

            # ì‹œë„ íšŸìˆ˜ ê°ì†Œ
            self.attempts_left = max(0, self.attempts_left - 1)

        self.status_label.setText(message)
        self.detect_btn.setEnabled(True if self.attempts_left > 0 or success else False)

        if not success and self.attempts_left == 0:
            # ğŸ”’ ë½ë‹¤ìš´ ì‹œì‘: 30ì´ˆ ì¹´ìš´íŠ¸ë‹¤ìš´
            self.start_lockdown(30)
        else:
            # ë½ë‹¤ìš´ì´ ì•„ë‹ˆë©´ ê¸°ì¡´ì²˜ëŸ¼ ëª‡ ì´ˆ í›„ ë©”ì‹œì§€ ì •ë¦¬
            self.clear_status()

    def _on_nodemcu_error(self, err: str):
        self.status_label.setText(f"NodeMCU ì—°ê²° ì‹¤íŒ¨: {err}")
        self.clear_status()

    # ëª¨ë“  ì¸ì¦ ê³¼ì • ì¢…ë¥˜ í›„ í™”ë©´ ì´ˆê¸°í™”
    def reset_to_main_scene(self):
        # MainScene.gifì˜ ì²« í”„ë ˆì„ì„ ë„ìš´ ì±„ ì •ì§€
        main_movie = QMovie("gif/MainScene.gif")
        main_movie.jumpToFrame(0)
        # QMovieê°ì²´ê°€ ì•„ë‹Œ í˜„ì¬ í”„ë ˆì„ë§Œ í‘œì‹œí•˜ë ¤ë©´ setPixmap
        self.label.setPixmap(main_movie.currentPixmap())
        # ë‹¤ìŒë²ˆ ì¬ìƒì„ ìœ„í•´ self.movieì—ë„ ì €ì¥
        self.movie = main_movie

    # ì¸ì¦ 3íšŒ ì‹¤íŒ¨ ì‹œ ë½ë‹¤ìš´
    def start_lockdown(self, seconds=30):
        """ë½ë‹¤ìš´ ì‹œì‘: seconds ë™ì•ˆ ì¹´ìš´íŠ¸ë‹¤ìš´ í‘œì‹œ"""
        self.lockdown_remaining = int(seconds)
        self.detect_btn.setEnabled(False)
        # ì•ˆë‚´ ë¬¸ì¥ ìˆ¨ê¹€(ìˆë‹¤ë©´)
        self.challenge_label.hide()
        # ì¦‰ì‹œ 1íšŒ ê°±ì‹ 
        self.status_label.setText(f"ì—°ì† ì‹¤íŒ¨ë¡œ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš” \n\n({self.lockdown_remaining}ì´ˆ)")
        # 1ì´ˆ ì£¼ê¸° ì¹´ìš´íŠ¸ë‹¤ìš´ ì‹œì‘
        self.lockdown_timer.start()

    def _tick_lockdown(self):
        """1ì´ˆë§ˆë‹¤ í˜¸ì¶œë˜ì–´ ë‚¨ì€ ì‹œê°„ ê°±ì‹ """
        self.lockdown_remaining -= 1
        if self.lockdown_remaining > 0:
            self.status_label.setText(f"ì—°ì† ì‹¤íŒ¨ë¡œ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš” \n\n({self.lockdown_remaining}ì´ˆ)")
        else:
            self.lockdown_timer.stop()
            self._unlock_after_lockdown()

    def _unlock_after_lockdown(self):
        """ë½ë‹¤ìš´ í•´ì œ: ë²„íŠ¼ í™œì„±í™” ë° ë©”ì‹œì§€ ì •ë¦¬"""
        # í˜¹ì‹œë¼ë„ ë‚¨ì•„ìˆìœ¼ë©´ ì •ì§€
        if self.lockdown_timer.isActive():
            self.lockdown_timer.stop()
        self.attempts_left = 3
        self.status_label.setText("ë‹¤ì‹œ ì‹œë„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        self.detect_btn.setEnabled(True)
        self.clear_status()

if __name__ == "__main__":
    app = QApplication(sys.argv)
    w = SmartDoorlockUI()
    w.show()
    sys.exit(app.exec_())
