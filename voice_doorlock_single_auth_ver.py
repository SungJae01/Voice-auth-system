# 1ì°¨, 2ì°¨ ì¸ì¦ê³¼ì • í†µí•©

import sys
import os
import random
import torch
import torchaudio
import librosa
import sounddevice as sd
import soundfile as sf
import numpy as np

from PyQt5.QtWidgets import (
    QApplication, QWidget, QVBoxLayout, QPushButton, QLabel,
    QMessageBox, QInputDialog, QDialog, QHBoxLayout
)
from PyQt5.QtCore import Qt, QTimer, QThread, pyqtSignal, QUrl, QSize
from PyQt5.QtMultimedia import QMediaPlayer, QMediaContent
from PyQt5.QtGui import QMovie
from transformers import Wav2Vec2Model, Wav2Vec2Processor
from speechbrain.pretrained import SpeakerRecognition
import whisper
from sentence_transformers import SentenceTransformer

import socket, time, logging


# ========== ì„¤ì • ==========
SAMPLE_RATE = 16000
RECORD_DURATION = 10
RECORD_SECONDS_LOGIN = 10
PROFILES_DIR = "profiles"
SIMILARITY_THRESHOLD = 0.5
ALPHA = 0.5
os.makedirs(PROFILES_DIR, exist_ok=True)

# ===== ë¡œê¹… ì„¤ì • =====
LOG_DIR = "logs"
os.makedirs(LOG_DIR, exist_ok=True)
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(os.path.join(LOG_DIR, "app.log"), encoding="utf-8"),
        logging.StreamHandler()
    ]
)

def _excepthook(exc_type, exc, tb):
    logging.error("Uncaught exception", exc_info=(exc_type, exc, tb))

import sys as _sys
_sys.excepthook = _excepthook

# AP ëª¨ë“œë¼ë©´ ê¸°ë³¸ IP, STA ëª¨ë“œë¼ë©´ ì‹œë¦¬ì–¼ ëª¨ë‹ˆí„°ì— ëœ¬ IPë¡œ ë°”ê¾¸ì„¸ìš”.
NODEMCU_HOST = "192.168.123.110"   # ë˜ëŠ” ì˜ˆ: "192.168.0.37"
NODEMCU_PORT = 7777

# ========== ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ==========
ecapa_model = SpeakerRecognition.from_hparams(
    source="speechbrain/spkrec-ecapa-voxceleb",
    savedir="ecapa_model"
)
wav2vec_model = Wav2Vec2Model.from_pretrained("facebook/wav2vec2-base")
wav2vec_processor = Wav2Vec2Processor.from_pretrained("facebook/wav2vec2-base")
wav2vec_model.eval()

sbert = SentenceTransformer("all-MiniLM-L6-v2")

# WhisperëŠ” MPS ë§ê³  CPU/CUDAë§Œ ì‚¬ìš© (MPSì—ì„œ sparse ì—ëŸ¬ ë°©ì§€)
WHISPER_DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
USE_FP16 = torch.cuda.is_available()  # CUDAì¼ ë•Œë§Œ fp16

whisper_model = whisper.load_model("small", device=WHISPER_DEVICE)

# Silero VAD ëª¨ë¸ ë¡œë”©
vad_model, utils = torch.hub.load(
    repo_or_dir='snakers4/silero-vad',
    model='silero_vad',
    trust_repo=True
)
(get_speech_timestamps, _, _, _, collect_chunks) = utils  # save_audio/read_audio/VADIterator ë¯¸ì‚¬ìš©

# ========== ì„ë² ë”©/ë¹„êµ í•¨ìˆ˜ ==========
def extract_pitch(y, sr, target_len=512):
    pitches, magnitudes = librosa.piptrack(y=y, sr=sr)
    vals = [pitches[magnitudes[:, t].argmax(), t] for t in range(pitches.shape[1])]
    vals = np.nan_to_num(vals)
    vals = librosa.util.fix_length(vals, size=target_len)
    return torch.tensor(vals).float().unsqueeze(0)

def get_ecapa_embedding(path):
    wav, sr = torchaudio.load(path)
    wav = torch.mean(wav, dim=0, keepdim=True)
    if sr != SAMPLE_RATE:
        wav = torchaudio.transforms.Resample(sr, SAMPLE_RATE)(wav)
    emb = ecapa_model.encode_batch(wav).squeeze(0)
    return emb.unsqueeze(0)

def get_wav2vec_pitch_embedding(path):
    y, sr = librosa.load(path, sr=SAMPLE_RATE)
    inputs = wav2vec_processor(y, sampling_rate=sr, return_tensors="pt").input_values
    with torch.no_grad():
        out = wav2vec_model(inputs)
    wav_emb = torch.mean(out.last_hidden_state, dim=1)
    pitch_emb = torch.mean(extract_pitch(y, sr), dim=1, keepdim=True) / 300.0
    return torch.cat((wav_emb, pitch_emb), dim=1)

def cosine_similarity(a, b):
    return torch.nn.functional.cosine_similarity(a, b).mean().item()

def compare_with_ensemble(emb1_dir, test_audio, alpha=ALPHA):
    try:
        emb1_ecapa = torch.load(os.path.join(emb1_dir, "ecapa.pt")).unsqueeze(0)
        emb1_wav = torch.load(os.path.join(emb1_dir, "wav2vec.pt")).unsqueeze(0)
    except (FileNotFoundError, OSError, RuntimeError) as e:
        logging.warning("Embedding load failed for %s: %s", emb1_dir, e)
        return -1e9  # ìœ íš¨í•˜ì§€ ì•Šì€ í”„ë¡œí•„ë¡œ ê°„ì£¼

    emb2_ecapa = get_ecapa_embedding(test_audio)
    emb2_wav = get_wav2vec_pitch_embedding(test_audio)

    sim_ecapa = cosine_similarity(emb1_ecapa, emb2_ecapa)
    sim_wav = cosine_similarity(emb1_wav, emb2_wav)
    return alpha * sim_wav + (1 - alpha) * sim_ecapa


def semantic_similarity(a: str, b: str, threshold: float = 0.7) -> bool:
    embs = sbert.encode([a, b], convert_to_tensor=True)
    sim = torch.nn.functional.cosine_similarity(embs[0], embs[1], dim=0).item()
    print(f"[ì˜ë¯¸ìœ ì‚¬ë„] cos={sim:.3f}")
    return sim >= threshold


def send_nodemcu(cmd: str, host=NODEMCU_HOST, port=NODEMCU_PORT, timeout=1.5, read_reply=False, retries=3, backoff=0.3):
    """
    NodeMCU TCP ì„œë²„(7777)ì— í•œ ì¤„ ëª…ë ¹ì„ ë³´ëƒ…ë‹ˆë‹¤. ì˜ˆì™¸/íƒ€ì„ì•„ì›ƒì— ëŒ€í•´ ì¬ì‹œë„(backoff)í•˜ë©°,
    read_reply=Trueë©´ ì²« ë¼ì¸ì„ ë°˜í™˜(ì—†ìœ¼ë©´ ê³µë°± ë¬¸ìì—´).
    """
    last_err = None
    for attempt in range(1, retries + 1):
        try:
            with socket.create_connection((host, port), timeout=timeout) as s:
                s.sendall((cmd.strip() + "\n").encode("utf-8"))
                if read_reply:
                    s.settimeout(timeout)
                    try:
                        data = s.recv(1024).decode("utf-8", errors="ignore").strip()
                        return data
                    except socket.timeout:
                        logging.warning("send_nodemcu reply timeout: %s", cmd)
                        return ""
                return ""
        except (ConnectionRefusedError, TimeoutError, OSError, socket.error) as e:
            last_err = e
            logging.warning("send_nodemcu attempt %d/%d failed: %s", attempt, retries, e)
            time.sleep(backoff * attempt)
    raise RuntimeError(f"NodeMCU ì—°ê²° ì‹¤íŒ¨: {last_err}")

# ë…¹ìŒ ì „ìš© ì›Œì»¤ ìŠ¤ë ˆë“œ ì •ì˜
class RecordWorker(QThread):
    finished = pyqtSignal(bool)   # ë…¹ìŒ ì„±ê³µ ì—¬ë¶€ë¥¼ ì „ë‹¬

    def __init__(self, path, duration):
        super().__init__()
        self.path = path
        self.duration = duration

    def run(self):
        try:
            ok = record_until_silence(self.path, self.duration)
        except Exception as e:
            logging.exception("RecordWorker error: %s", e)
            ok = False
        self.finished.emit(ok)


# 2ì°¨ ì¸ì¦ ì „ìš© ì›Œì»¤ ìŠ¤ë ˆë“œ ì •ì˜
class SecondAuthWorker(QThread):
    finished = pyqtSignal(bool, str)

    def __init__(self, user, sentence, attempts):
        super().__init__()
        self.user = user
        self.expected_sentence = sentence
        self.attempts = attempts

    def run(self):
        # 1) ë…¹ìŒ
        try:
            ok = record_until_silence("second.wav", RECORD_SECONDS_LOGIN)
        except Exception as e:
            logging.exception("SecondAuthWorker record error: %s", e)
            self.finished.emit(False, "ë…¹ìŒ ì‹¤íŒ¨")
            return
        if not ok:
            self.finished.emit(False, "ìŒì„± ë¯¸ê°ì§€")
            return

        # 2) Whisper STT & ì˜ë¯¸ ë¹„êµ
        try:
            result = whisper_model.transcribe(
                "second.wav",
                language="ko",
                temperature=0.0,
                beam_size=1, best_of=1,
                condition_on_previous_text=False,
                fp16=USE_FP16,
                initial_prompt="ìŠ¤ë§ˆíŠ¸ ë„ì–´ë½, ì¸ì¦, ê´‘í™”ë¬¸, ë‚ ì”¨"
            )
            spoken = result["text"].strip().lower()
        except Exception as e:
            logging.exception("Whisper error: %s", e)
            self.finished.emit(False, "ìŒì„± ì¸ì‹ ì‹¤íŒ¨")
            return

        if not semantic_similarity(self.expected_sentence.lower(), spoken):
            self.finished.emit(False, "ë¬¸ì¥ ì˜ë¯¸ ë¶ˆì¼ì¹˜")
            return

        # 3) í™”ì ìœ ì‚¬ë„â€¦
        try:
            score = compare_with_ensemble(os.path.join(PROFILES_DIR, self.user),
                                        "second.wav", alpha=ALPHA)
        except Exception as e:
            logging.exception("Embedding compare error: %s", e)
            self.finished.emit(False, "í”„ë¡œí•„ ë¹„êµ ì‹¤íŒ¨")
            return
        print(f"[í™”ììœ ì‚¬ë„] cos={score:.3f}")
        success = score >= SIMILARITY_THRESHOLD
        msg = f"{self.user}ë‹˜ ì•ˆë…•í•˜ì„¸ìš”! ë„ì–´ë½ì´ ì—´ë ¸ìŠµë‹ˆë‹¤" if success else f"ë‚¨ì€ ì‹œë„ {self.attempts-1}íšŒ"
        self.finished.emit(success, msg)

class NodeMCUWorker(QThread):
    error = pyqtSignal(str)

    def __init__(self, open_ms=7000, polls=8, interval=0.4, parent=None):
        super().__init__(parent)
        self.open_ms = open_ms
        self.polls = polls
        self.interval = interval
        self._stop = False

    def stop(self):
        self._stop = True

    def run(self):
        try:
            send_nodemcu(f"OPEN {self.open_ms}")
            for _ in range(self.polls):
                if self._stop:
                    break
                send_nodemcu("STATUS")
                time.sleep(self.interval)
        except Exception as e:
            self.error.emit(str(e))



# ========== ë…¹ìŒ ë° VAD í•¨ìˆ˜ ==========
def record_until_silence(path,
                        max_duration,
                        block_duration=0.5,
                        silence_blocks_thresh=2):
    """
    â€¢ with InputStream: ë¸”ë¡ ì¢…ë£Œ ì‹œì ì— ìŠ¤íŠ¸ë¦¼ì´ ìë™ close â†’ semaphore ëˆ„ìˆ˜ ë°©ì§€
    â€¢ block_duration ì´ˆì”© ì½ì–´ì„œ VAD ê²€ì‚¬
    â€¢ speech_started í›„ silence_blocks_thresh ì—°ì† ë¬´ìŒ ì‹œ ë…¹ìŒ ì¢…ë£Œ
    """
    blocks = []
    speech_started = False
    silence_blocks = 0
    max_blocks = int(max_duration / block_duration)

    try:
        with sd.InputStream(samplerate=SAMPLE_RATE, channels=1, dtype='float32') as stream:
            for _ in range(max_blocks):
                audio, _ = stream.read(int(SAMPLE_RATE * block_duration))
                if audio is None or len(audio) == 0:
                    continue
                blocks.append(audio)

                wav = torch.from_numpy(audio.squeeze()).float()
                ts = get_speech_timestamps(wav, vad_model, sampling_rate=SAMPLE_RATE)
                if ts:
                    speech_started = True
                    silence_blocks = 0
                elif speech_started:
                    silence_blocks += 1

                if speech_started and silence_blocks >= silence_blocks_thresh:
                    break
    except Exception as e:
        logging.exception("Audio input error: %s", e)
        return False

    if not blocks:
        return False

    try:
        full = np.concatenate(blocks, axis=0)
        wav_full = torch.from_numpy(full.squeeze()).float()
        speech_ts = get_speech_timestamps(wav_full, vad_model, sampling_rate=SAMPLE_RATE)
        if not speech_ts:
            return False
        voiced = collect_chunks(speech_ts, wav_full)
        sf.write(path, voiced.numpy(), SAMPLE_RATE)
        return True
    except Exception as e:
        logging.exception("Post-record/VAD error: %s", e)
        return False


# ========== ë…¹ìŒ ì•ˆë‚´ ë‹¤ì´ì–¼ë¡œê·¸ ==========
class RecordingDialog(QDialog):
    def __init__(self, sentence, record_func, path, duration):
        super().__init__()
        self.setWindowTitle("ğŸ™ ë…¹ìŒ ì•ˆë‚´")
        self.setFixedSize(400, 200)
        self.record_func = record_func
        self.path = path
        self.duration = duration

        lay = QVBoxLayout()
        lbl = QLabel(f"ğŸ“¢ ë‹¤ìŒ ë¬¸ì¥ì„ ë˜ë°•ë˜ë°• ì½ì–´ì£¼ì„¸ìš”:\n\nã€ {sentence} ã€")
        lbl.setWordWrap(True)
        lay.addWidget(lbl)

        btn = QPushButton("ğŸ¤ ë…¹ìŒ ì‹œì‘")
        btn.clicked.connect(self._do_record)
        lay.addWidget(btn)

        self.setLayout(lay)

    def _do_record(self):
        self.record_func(self.path, self.duration)
        self.accept()

        

# ========== ë©”ì¸ UI ==========
class SmartDoorlockUI(QWidget):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("ğŸ” ìŠ¤ë§ˆíŠ¸ ë„ì–´ë½ ì‹œë®¬ë ˆì´í„°")
        self.setGeometry(1800, 0, 500, 1285)    # ì‹¤ì œ ì†Œí˜• LCD í™”ë©´ ë¹„ìœ¨ê³¼ ìœ ì‚¬í•˜ê²Œ
        self.setStyleSheet("background-color: white;")
        self.auth_fail_count = 0    # ì‹¤íŒ¨ íšŸìˆ˜ ì´ˆê¸°í™”
        self.second_attempts = 3    # 2ì°¨ ì¸ì¦ ì´ ì‹œë„ íšŸìˆ˜

        # â”€â”€ ë©”ì¸ ë ˆì´ì•„ì›ƒ (í•œ ë²ˆë§Œ!) â”€â”€
        main_lay = QVBoxLayout(self)
        main_lay.setContentsMargins(0,0,0,0)

        # â”€â”€ ì• ë‹ˆë©”ì´ì…˜ ë¼ë²¨ & ë…¹ìŒì¤‘ ë ˆì´ë¸” ì¤€ë¹„ â”€â”€
        self.label = QLabel(self)
        self.label.setFixedSize(500, 500)
        self.label.setAlignment(Qt.AlignCenter)
        self.movie = QMovie("gif/MainScene.gif")
        self.movie.setScaledSize(QSize(250, 250))
        self.label.setFixedHeight(500)
        # ìµœì´ˆì—” ì¬ìƒí•˜ì§€ ì•Šê³  ì²« í”„ë ˆì„ë§Œ
        self.movie.jumpToFrame(0)
        self.label.setPixmap(self.movie.currentPixmap())
        main_lay.addWidget(self.label)

        # â”€â”€ 2ì°¨ ì¸ì¦ ë¬¸ì¥ í‘œì‹œìš© ë ˆì´ë¸” â”€â”€
        self.challenge_label = QLabel("", self)
        self.challenge_label.setAlignment(Qt.AlignCenter)
        self.challenge_label.setStyleSheet("color: #bbbbbf; font-size: 23px;")
        self.challenge_label.setFixedHeight(100)
        self.challenge_label.hide()
        main_lay.addWidget(self.challenge_label)

        # â”€â”€ ë¯¸ë””ì–´ í”Œë ˆì´ì–´ ì¤€ë¹„ â”€â”€
        self.player = QMediaPlayer(self)

        # â”€â”€ ìƒíƒœ ë©”ì‹œì§€ ë ˆì´ë¸” ì¶”ê°€ â”€â”€
        self.status_label = QLabel("", self)
        self.status_label.setAlignment(Qt.AlignCenter)
        self.status_label.setStyleSheet("""
            color: #bbbbbf;
            font-size: 23px;
            padding: 8px;
        """)
        self.status_label.setFixedHeight(100)
        main_lay.addWidget(self.status_label)

        # â”€â”€ â€œë…¹ìŒì¤‘â€ í…ìŠ¤íŠ¸ ë ˆì´ë¸” â”€â”€
        self.recording_label = QLabel("ë…¹ìŒì¤‘â€¦", self)
        self.recording_label.setAlignment(Qt.AlignCenter)
        self.recording_label.setStyleSheet("color: #bbbbbf; font-size: 23px;")
        self.recording_label.setFixedHeight(60)
        self.recording_label.hide()               # ì´ˆê¸°ì—ëŠ” ìˆ¨ê¹€
        main_lay.addWidget(self.recording_label)

        # â”€â”€ ìœ„ì ¯ë“¤ ì‚¬ì´ì˜ ë‚¨ëŠ” ê³µê°„ì„ ì „ë¶€ ì°¨ì§€í•  ìŠ¤íŠ¸ë ˆì¹˜ ì¶”ê°€ â”€â”€
        main_lay.addStretch()

        # â”€â”€ ë²„íŠ¼ ë ˆì´ì•„ì›ƒ â”€â”€
        hbtn = QHBoxLayout()
        self.detect_btn = QPushButton("ğŸš¶ ì‚¬ìš©ì ì ‘ê·¼ ê°ì§€"); 
        self.detect_btn.clicked.connect(self.on_user_detected)
        self.detect_btn.setStyleSheet("""
            QPushButton {
                background-color: #3498db;
                color: white;
                border: none;
                padding: 8px 16px;
                border-radius: 4px;
            }
        """)
        self.create_btn = QPushButton("â• í”„ë¡œí•„ ìƒì„±");     
        self.create_btn.clicked.connect(self.create_profile)
        self.create_btn.setStyleSheet("""
            QPushButton {
                background-color: #3498db;
                color: white;
                border: none;
                padding: 8px 16px;
                border-radius: 4px;
            }
        """)
        hbtn.addWidget(self.detect_btn); hbtn.addWidget(self.create_btn)
        main_lay.addLayout(hbtn)

        self.profiles = []
        self.load_profiles()
        
    def create_profile(self):
        name, ok = QInputDialog.getText(self, "í”„ë¡œí•„ ìƒì„±", "ì‚¬ìš©ì ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”:")
        if not ok or not name.strip():
            return
        name = name.strip()
        profile_dir = os.path.join(PROFILES_DIR, name)
        if os.path.exists(profile_dir):
            QMessageBox.warning(self, "ì¤‘ë³µ", "ì´ë¯¸ ì¡´ì¬í•˜ëŠ” í”„ë¡œí•„ì…ë‹ˆë‹¤.")
            return
        os.makedirs(profile_dir, exist_ok=True)

        sentences = [
            "ìŒì„±ìœ¼ë¡œ ë¬¸ì„ ì—´ê² ìŠµë‹ˆë‹¤. ì§€ê¸ˆë¶€í„° ì¸ì¦ì„ ì‹œì‘í•©ë‹ˆë‹¤.",
            "ì´ ë¬¸ì¥ì„ ì •í™•íˆ ë§í•˜ë©´ ì ê¸ˆì¥ì¹˜ê°€ í•´ì œë©ë‹ˆë‹¤.",
            "ì§€ê¸ˆ ë“¤ë¦¬ëŠ” ì´ ëª©ì†Œë¦¬ëŠ” ì €ë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë³´ì•ˆ ì—´ì‡ ì…ë‹ˆë‹¤.",
            "ìŠ¤ë§ˆíŠ¸ ë„ì–´ ì‹œìŠ¤í…œì„ í†µí•´ ì§‘ì— ì•ˆì „í•˜ê²Œ ë“¤ì–´ê°€ê³  ì‹¶ìŠµë‹ˆë‹¤.",
            "ì´ì œ ì œ ìŒì„±ìœ¼ë¡œ ë¬¸ì„ ì—´ ìˆ˜ ìˆëŠ” ì‹œëŒ€ê°€ ì™”ìŠµë‹ˆë‹¤. ì—´ì–´ì£¼ì„¸ìš”."
        ]

        ecapa_embs, wav_embs = [], []
        for i, sentence in enumerate(sentences):
            rec_path = os.path.join(profile_dir, f"rec{i+1}.wav")
            dialog = RecordingDialog(
                sentence,
                record_until_silence,
                rec_path,
                RECORD_DURATION
            )
            dialog.exec_()

            ecapa_embs.append(get_ecapa_embedding(rec_path).squeeze(0))
            wav_embs.append(get_wav2vec_pitch_embedding(rec_path).squeeze(0))

        # í‰ê·  ì„ë² ë”© ì €ì¥
        torch.save(torch.stack(ecapa_embs).mean(0), os.path.join(profile_dir, "ecapa.pt"))
        torch.save(torch.stack(wav_embs).mean(0),  os.path.join(profile_dir, "wav2vec.pt"))

        QMessageBox.information(self, "ì™„ë£Œ", "í”„ë¡œí•„ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        self.load_profiles()

    def load_profiles(self):
        try:
            self.profiles = [d for d in os.listdir(PROFILES_DIR)
                            if os.path.isdir(os.path.join(PROFILES_DIR, d))]
        except Exception as e:
            logging.exception("load_profiles error: %s", e)
            self.profiles = []

    def clear_status(self, delay=3000):
        """delay(ms) ë’¤ì— ë©”ì‹œì§€ ì§€ìš°ê¸°."""
        QTimer.singleShot(delay, lambda: self.status_label.setText(""))

    def on_user_detected(self):
        # 1) MP3 ì¬ìƒ â”€â”€
        mp3_path = os.path.abspath("mp3/Apple Intelligence Sound Effect.mp3")  # ì¬ìƒí•  íŒŒì¼ ê²½ë¡œ
        url = QUrl.fromLocalFile(mp3_path)
        media = QMediaContent(url)
        self.player.setMedia(media)
        self.player.play()

        # 2) ì‚¬ìš©ì ì ‘ê·¼ ê°ì§€ â†’ ì• ë‹ˆë©”ì´ì…˜ ì¬ìƒ + ë…¹ìŒì¤‘ í…ìŠ¤íŠ¸ ë³´ì´ê¸°
        self.label.setMovie(self.movie)
        self.movie.start()
        self.recording_label.setText("ë…¹ìŒì¤‘â€¦")
        self.recording_label.show()
        self.detect_btn.setEnabled(False)

        # 3) ì›Œì»¤ ìŠ¤ë ˆë“œë¡œ ë…¹ìŒ ì‹œì‘
        self.recorder = RecordWorker("login.wav", RECORD_SECONDS_LOGIN)
        self.recorder.finished.connect(self.on_record_finished)
        self.recorder.start()

    def on_record_finished(self, ok: bool):
        # ì´ ìŠ¬ë¡¯ì€ ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤.
        self.movie.stop()
        self.recording_label.hide()
        self.detect_btn.setEnabled(True)

        if not ok:
            # ì˜¤ë¥˜ MP3 ì¬ìƒ
            mp3_path = os.path.abspath("mp3/Mac Error Sound Effect.mp3")  # ì¬ìƒí•  íŒŒì¼ ê²½ë¡œ
            url = QUrl.fromLocalFile(mp3_path)
            media = QMediaContent(url)
            self.player.setMedia(media)
            self.player.play()

            # ì˜¤ë¥˜ìš© GIF êµì²´
            error_movie = QMovie("gif/Error animation.gif")
            self.label.setMovie(error_movie)
            error_movie.setSpeed(75)  # ê¸°ë³¸ ì†ë„ì˜ 75% â†’ ì ˆë°˜ ì†ë„ë¡œ ì¬ìƒ
            error_movie.start()

            self.status_label.setText("ì‹¤íŒ¨: ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            self.clear_status()
            return

        # ë…¹ìŒì´ ì„±ê³µí–ˆìœ¼ë‹ˆ 1ì°¨ ì¸ì¦ ë¡œì§ ì‹¤í–‰
        self.process_first_auth()

    def process_first_auth(self):
        if not self.profiles:
            # ì˜¤ë¥˜ MP3 ì¬ìƒ
            mp3_path = os.path.abspath("mp3/Mac Error Sound Effect.mp3")  # ì¬ìƒí•  íŒŒì¼ ê²½ë¡œ
            url = QUrl.fromLocalFile(mp3_path)
            media = QMediaContent(url)
            self.player.setMedia(media)
            self.player.play()

            # ì˜¤ë¥˜ìš© GIF êµì²´
            error_movie = QMovie("gif/Error animation.gif")
            self.label.setMovie(error_movie)
            error_movie.setSpeed(75)  # ê¸°ë³¸ ì†ë„ì˜ 75% â†’ ì ˆë°˜ ì†ë„ë¡œ ì¬ìƒ
            error_movie.start()

            self.status_label.setText("ì˜¤ë¥˜: ë“±ë¡ëœ í”„ë¡œí•„ì´ ì—†ìŠµë‹ˆë‹¤.")
            self.clear_status()
            return

        # ë…¹ìŒ ëë‚¬ìœ¼ë‹ˆ â€œë…¹ìŒì¤‘â€ í…ìŠ¤íŠ¸ ìˆ¨ê¸°ê³  ì™„ë£Œ ì• ë‹ˆë©”ì´ì…˜ìœ¼ë¡œ êµì²´
        self.movie.stop()

        best_match, best_score = None, 0.0

        print("1ì°¨ ì¸ì¦ ê²°ê³¼")
        for p in self.profiles:
            profile_dir = os.path.join(PROFILES_DIR, p)
            combined = compare_with_ensemble(profile_dir, "login.wav")
            print(f"[ìœ ì‚¬ë„] {p}: {combined:.4f}")

            if combined > best_score:
                best_score = combined
                best_match = p

        if best_score >= SIMILARITY_THRESHOLD:
            success_movie = QMovie("gif/Success.gif")
            self.label.setMovie(success_movie)
            success_movie.setSpeed(75)
            success_movie.start()
            self.status_label.setText(f"1ì°¨ ì¸ì¦ ì„±ê³µ: {best_match}ë‹˜, ì•ˆë…•í•˜ì„¸ìš”!")
            self.start_second_auth(best_match)
            try:
                send_nodemcu("PING")
                send_nodemcu("STATUS")
            except Exception as e:
                self.status_label.setText(f"NodeMCU ì—°ê²° ì‹¤íŒ¨: {e}")
                self.clear_status()
        else:
            # ì˜¤ë¥˜ MP3 ì¬ìƒ
            mp3_path = os.path.abspath("mp3/Mac Error Sound Effect.mp3")  # ì¬ìƒí•  íŒŒì¼ ê²½ë¡œ
            url = QUrl.fromLocalFile(mp3_path)
            media = QMediaContent(url)
            self.player.setMedia(media)
            self.player.play()

            # ì˜¤ë¥˜ìš© GIF êµì²´
            error_movie = QMovie("gif/Error animation.gif")
            self.label.setMovie(error_movie)
            error_movie.setSpeed(75)
            error_movie.start()

            self.status_label.setText("ì¸ì¦ ì‹¤íŒ¨: ë“±ë¡ë˜ì§€ ì•Šì€ ìŒì„±ì…ë‹ˆë‹¤.")
        self.clear_status()

    def start_second_auth(self, user):
        # 1) ëœë¤ ë¬¸ì¥ ì„ íƒ
        sentence = random.choice([
            "ì„œìš¸ì˜ ì¤‘ì‹¬ì€ ê´‘í™”ë¬¸ì…ë‹ˆë‹¤.",
            "ì˜¤ëŠ˜ë„ ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”.",
            "ë´„ì—ëŠ” ê½ƒì´ í”¼ê³  ìƒˆê°€ ë‚ ì•„ìš”."
        ])
        # 2) í™”ë©´ì— ë³´ì—¬ì£¼ê¸°
        self.challenge_label.setText(f"2ì°¨ ì¸ì¦\n\nã€Œ{sentence}ã€")
        self.challenge_label.show()

        # 3) ì• ë‹ˆë©”ì´ì…˜ ì¬ìƒ
        auth_movie = QMovie("gif/Find people.gif")
        self.label.setMovie(auth_movie)
        auth_movie.setSpeed(75)
        auth_movie.start()

        # 4) ë²„íŠ¼ ì ê¸ˆ
        self.detect_btn.setEnabled(False)

        # 5) ì›Œì»¤ì— sentenceë„ ë„˜ê¸°ê¸°
        self.second_worker = SecondAuthWorker(
            user=user,
            sentence=sentence,
            attempts=self.second_attempts
        )
        self.second_worker.finished.connect(self.on_second_auth_finished)
        self.second_worker.start()

    def on_second_auth_finished(self, success, message):
        # ì±Œë¦°ì§€ ë¬¸ì¥ ìˆ¨ê¸°ê¸°
        self.challenge_label.hide()
        # ê¸°ì¡´ ì„±ê³µ/ì‹¤íŒ¨ ì²˜ë¦¬â€¦
        movie = QMovie("gif/Success.gif" if success else "gif/Error animation.gif")
        self.label.setMovie(movie)
        movie.start()
        self.status_label.setText(message)
        self.detect_btn.setEnabled(True)
        if not success:
            self.clear_status()
            self.second_attempts -= 1
            return
        self.clear_status(delay=5000)

        # âœ… ì¸ì¦ ì„±ê³µ: NodeMCUì— ê°œë°© í„ìŠ¤ ì „ì†¡ (ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ)
        self.nodemcu_worker = NodeMCUWorker(open_ms=7000, polls=8, interval=0.4)
        self.nodemcu_worker.error.connect(self._on_nodemcu_error)
        self.nodemcu_worker.start()

        # ì„±ê³µì¼ ë•Œë§Œ 5ì´ˆ ë’¤ì— ë©”ì¸ í™”ë©´ìœ¼ë¡œ ë¦¬ì…‹
        QTimer.singleShot(5000, self.reset_to_main_scene)

    def _on_nodemcu_error(self, err: str):
        self.status_label.setText(f"NodeMCU ì—°ê²° ì‹¤íŒ¨: {err}")
        self.clear_status()

    def reset_to_main_scene(self):
        # MainScene.gifì˜ ì²« í”„ë ˆì„ì„ ë„ìš´ ì±„ ì •ì§€
        main_movie = QMovie("gif/MainScene.gif")
        main_movie.setScaledSize(QSize(250, 250))
        main_movie.jumpToFrame(0)
        # QMovieê°ì²´ê°€ ì•„ë‹Œ í˜„ì¬ í”„ë ˆì„ë§Œ í‘œì‹œí•˜ë ¤ë©´ setPixmap
        self.label.setPixmap(main_movie.currentPixmap())
        # ë‹¤ìŒë²ˆ ì¬ìƒì„ ìœ„í•´ self.movieì—ë„ ì €ì¥
        self.movie = main_movie


if __name__ == "__main__":
    app = QApplication(sys.argv)
    w = SmartDoorlockUI()
    w.show()
    sys.exit(app.exec_())
