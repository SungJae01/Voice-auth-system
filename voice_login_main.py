import sys
import os
import random
import torch
import torchaudio
import librosa
import sounddevice as sd
import soundfile as sf
import numpy as np
import math

from PyQt5.QtWidgets import (
    QApplication, QWidget, QVBoxLayout, QPushButton, QLabel,
    QMessageBox, QInputDialog, QDialog, QHBoxLayout
)
from PyQt5.QtCore import Qt, QTimer, QThread, pyqtSignal, QUrl, QSize
from PyQt5.QtMultimedia import QMediaPlayer, QMediaContent
from PyQt5.QtGui import QMovie
from transformers import Wav2Vec2Model, Wav2Vec2Processor
from speechbrain.pretrained import SpeakerRecognition
import whisper
from sentence_transformers import SentenceTransformer

# ========== ì„¤ì • ==========
SAMPLE_RATE = 16000
RECORD_DURATION = 10
RECORD_SECONDS_LOGIN = 10
PROFILES_DIR = "profiles"
SIMILARITY_THRESHOLD = 0.5
ALPHA = 0.5
os.makedirs(PROFILES_DIR, exist_ok=True)

# ========== ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ==========
ecapa_model = SpeakerRecognition.from_hparams(
    source="speechbrain/spkrec-ecapa-voxceleb",
    savedir="ecapa_model"
)
wav2vec_model = Wav2Vec2Model.from_pretrained("facebook/wav2vec2-base")
wav2vec_processor = Wav2Vec2Processor.from_pretrained("facebook/wav2vec2-base")
wav2vec_model.eval()

#whisper_model = whisper.load_model("large-v3-turbo")  # ë˜ëŠ” "base", "small" ë“±
sbert = SentenceTransformer("all-MiniLM-L6-v2")

# WhisperëŠ” MPS ë§ê³  CPU/CUDAë§Œ ì‚¬ìš© (MPSì—ì„œ sparse ì—ëŸ¬ ë°©ì§€)
WHISPER_DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
USE_FP16 = torch.cuda.is_available()  # CUDAì¼ ë•Œë§Œ fp16

whisper_model = whisper.load_model("small", device=WHISPER_DEVICE)

# Silero VAD ëª¨ë¸ ë¡œë”©
vad_model, utils = torch.hub.load(
    repo_or_dir='snakers4/silero-vad',
    model='silero_vad',
    trust_repo=True
)
(get_speech_timestamps, save_audio, read_audio, VADIterator, collect_chunks) = utils

# ========== ì„ë² ë”©/ë¹„êµ í•¨ìˆ˜ ==========
def extract_pitch(y, sr, target_len=512):
    pitches, magnitudes = librosa.piptrack(y=y, sr=sr)
    vals = [pitches[magnitudes[:, t].argmax(), t] for t in range(pitches.shape[1])]
    vals = np.nan_to_num(vals)
    vals = librosa.util.fix_length(vals, size=target_len)
    return torch.tensor(vals).float().unsqueeze(0)

def get_ecapa_embedding(path):
    wav, sr = torchaudio.load(path)
    wav = torch.mean(wav, dim=0, keepdim=True)
    if sr != SAMPLE_RATE:
        wav = torchaudio.transforms.Resample(sr, SAMPLE_RATE)(wav)
    emb = ecapa_model.encode_batch(wav).squeeze(0)
    return emb.unsqueeze(0)

def get_wav2vec_pitch_embedding(path):
    y, sr = librosa.load(path, sr=SAMPLE_RATE)
    inputs = wav2vec_processor(y, sampling_rate=sr, return_tensors="pt").input_values
    with torch.no_grad():
        out = wav2vec_model(inputs)
    wav_emb = torch.mean(out.last_hidden_state, dim=1)
    pitch_emb = torch.mean(extract_pitch(y, sr), dim=1, keepdim=True) / 300.0
    return torch.cat((wav_emb, pitch_emb), dim=1)

def cosine_similarity(a, b):
    return torch.nn.functional.cosine_similarity(a, b).mean().item()

def compare_with_ensemble(emb1_dir, test_audio, alpha=ALPHA):
    emb1_ecapa = torch.load(os.path.join(emb1_dir, "ecapa.pt")).unsqueeze(0)
    emb1_wav = torch.load(os.path.join(emb1_dir, "wav2vec.pt")).unsqueeze(0)

    emb2_ecapa = get_ecapa_embedding(test_audio)
    emb2_wav = get_wav2vec_pitch_embedding(test_audio)

    sim_ecapa = cosine_similarity(emb1_ecapa, emb2_ecapa)
    sim_wav = cosine_similarity(emb1_wav, emb2_wav)
    
    return alpha * sim_wav + (1 - alpha) * sim_ecapa    
    # ECAPA ìœ ì‚¬ë„ì— Wav2Vec2+Pitchì˜ ìœ ì‚¬ë„ë¥¼ ì¼ì • ë¹„ìœ¨ë¡œ í•©ì³ ìœ ì‚¬ë„ ë°˜í™˜
    # ì´ë¶€ë¶„ì˜ ìˆ˜ì‹ì„ ë³€ê²½í•´ì„œ ë” ë³´ì•ˆì„±ì´ ë†’ì€ ìœ ì‚¬ë„ ê°’ì„ ë°˜í™˜í•  ì˜ˆì •

def semantic_similarity(a: str, b: str, threshold: float = 0.7) -> bool:
    embs = sbert.encode([a, b], convert_to_tensor=True)
    sim = torch.nn.functional.cosine_similarity(embs[0], embs[1], dim=0).item()
    print(f"[ì˜ë¯¸ìœ ì‚¬ë„] cos={sim:.3f}")
    return sim >= threshold

# ë…¹ìŒ ì „ìš© ì›Œì»¤ ìŠ¤ë ˆë“œ ì •ì˜
class RecordWorker(QThread):
    finished = pyqtSignal(bool)   # ë…¹ìŒ ì„±ê³µ ì—¬ë¶€ë¥¼ ì „ë‹¬

    def __init__(self, path, duration):
        super().__init__()
        self.path = path
        self.duration = duration

    def run(self):
        # ì´ run() ì•ˆì—ì„œë§Œ ë¸”ë¡œí‚¹ ë…¹ìŒì´ ì´ë¤„ì§‘ë‹ˆë‹¤.
        ok = record_until_silence(self.path, self.duration)
        self.finished.emit(ok)

# 1ì°¨ ì¸ì¦ ì „ìš© ì›Œì»¤ ìŠ¤ë ˆë“œ ì •ì˜
class AuthWorker(QThread):
    finished = pyqtSignal(bool, str)  # (ì„±ê³µì—¬ë¶€, ë©”ì‹œì§€)

    def __init__(self, profiles):
        super().__init__()
        self.profiles = profiles

    def run(self):
        # 1ì°¨ ì¸ì¦ ë¡œì§ ì˜ˆì‹œ
        best_match, best_score = None, 0.0
        for p in self.profiles:
            score = compare_with_ensemble(os.path.join(PROFILES_DIR, p), "login.wav")
            if score > best_score:
                best_score, best_match = score, p

        success = best_score >= SIMILARITY_THRESHOLD
        msg = f"{best_match}ë‹˜ 1ì°¨ ì¸ì¦ ì„±ê³µ" if success else "1ì°¨ ì¸ì¦ ì‹¤íŒ¨"
        self.finished.emit(success, msg)

# 2ì°¨ ì¸ì¦ ì „ìš© ì›Œì»¤ ìŠ¤ë ˆë“œ ì •ì˜
class SecondAuthWorker(QThread):
    finished = pyqtSignal(bool, str)

    def __init__(self, user, sentence, attempts):
        super().__init__()
        self.user = user
        self.expected_sentence = sentence
        self.attempts = attempts

    def run(self):
        # 1) ë…¹ìŒ
        ok = record_until_silence("second.wav", RECORD_SECONDS_LOGIN)
        if not ok:
            self.finished.emit(False, "ìŒì„± ë¯¸ê°ì§€")
            return

        # 2) Whisper STT & ì˜ë¯¸ ë¹„êµ
        #result = whisper_model.transcribe("second.wav", fp16=False)
        result = whisper_model.transcribe(
            "second.wav",
            language="ko",                 # ì–¸ì–´ ê³ ì • â†’ ì†ë„/ì•ˆì •ì„±â†‘
            temperature=0.0,               # íƒìƒ‰ ìµœì†Œí™”
            beam_size=1, best_of=1,        # ë¹”ì„œì¹˜ ì¶•ì†Œ
            condition_on_previous_text=False,
            fp16=USE_FP16,                 # ìœ„ì—ì„œ ê²°ì •í•œ ê°’
            initial_prompt="ìŠ¤ë§ˆíŠ¸ ë„ì–´ë½, ì¸ì¦, ê´‘í™”ë¬¸, ë‚ ì”¨"  # (ì„ íƒ) ìì£¼ ë‚˜ì˜¤ëŠ” ë‹¨ì–´ íŒíŠ¸
        )
        spoken = result["text"].strip().lower()
        if not semantic_similarity(self.expected_sentence.lower(), spoken):
            self.finished.emit(False, "ë¬¸ì¥ ì˜ë¯¸ ë¶ˆì¼ì¹˜")
            return

        # 3) í™”ì ìœ ì‚¬ë„â€¦
        score = compare_with_ensemble(os.path.join(PROFILES_DIR, self.user),
                                    "second.wav", alpha=ALPHA)
        print(f"[í™”ììœ ì‚¬ë„] cos={score:.3f}")
        success = score >= SIMILARITY_THRESHOLD
        msg = "ì¸ì¦ ì„±ê³µ! \n ë„ì–´ë½ì´ ì—´ë ¸ìŠµë‹ˆë‹¤." if success else f"ë‚¨ì€ ì‹œë„ {self.attempts-1}íšŒ"
        self.finished.emit(success, msg)

# ========== ë…¹ìŒ ë° VAD í•¨ìˆ˜ ==========
def record_until_silence(path,
                        max_duration,
                        block_duration=0.5,
                        silence_blocks_thresh=2):
    """
    â€¢ with InputStream: ë¸”ë¡ ì¢…ë£Œ ì‹œì ì— ìŠ¤íŠ¸ë¦¼ì´ ìë™ close â†’ semaphore ëˆ„ìˆ˜ ë°©ì§€
    â€¢ block_duration ì´ˆì”© ì½ì–´ì„œ VAD ê²€ì‚¬
    â€¢ speech_started í›„ silence_blocks_thresh ì—°ì† ë¬´ìŒ ì‹œ ë…¹ìŒ ì¢…ë£Œ
    """
    blocks = []
    speech_started = False
    silence_blocks = 0
    max_blocks = int(max_duration / block_duration)
    
    # â”€â”€ InputStreamì„ contextâ€managerë¡œ ì—´ê¸° â”€â”€
    with sd.InputStream(samplerate=SAMPLE_RATE, channels=1, dtype='float32') as stream:
        for _ in range(max_blocks):
            audio, _ = stream.read(int(SAMPLE_RATE * block_duration))
            blocks.append(audio)

            wav = torch.from_numpy(audio.squeeze()).float()
            ts = get_speech_timestamps(wav, vad_model, sampling_rate=SAMPLE_RATE)
            if ts:
                speech_started = True
                silence_blocks = 0
            elif speech_started:
                silence_blocks += 1

            if speech_started and silence_blocks >= silence_blocks_thresh:
                break

    # â”€â”€ ë…¹ìŒ ì´í›„ í›„ì²˜ë¦¬ (VADë¡œ ë¬´ìŒ ì œê±° & íŒŒì¼ ì €ì¥) â”€â”€
    full = np.concatenate(blocks, axis=0)
    wav_full = torch.from_numpy(full.squeeze()).float()
    speech_ts = get_speech_timestamps(wav_full, vad_model, sampling_rate=SAMPLE_RATE)
    if not speech_ts:
        return False
    voiced = collect_chunks(speech_ts, wav_full)
    sf.write(path, voiced.numpy(), SAMPLE_RATE)
    return True

# ========== ë…¹ìŒ ì•ˆë‚´ ë‹¤ì´ì–¼ë¡œê·¸ ==========
class RecordingDialog(QDialog):
    def __init__(self, sentence, record_func, path, duration):
        super().__init__()
        self.setWindowTitle("ğŸ™ ë…¹ìŒ ì•ˆë‚´")
        self.setFixedSize(400, 200)
        self.record_func = record_func
        self.path = path
        self.duration = duration

        lay = QVBoxLayout()
        lbl = QLabel(f"ğŸ“¢ ë‹¤ìŒ ë¬¸ì¥ì„ ë˜ë°•ë˜ë°• ì½ì–´ì£¼ì„¸ìš”:\n\nã€ {sentence} ã€")
        lbl.setWordWrap(True)
        lay.addWidget(lbl)

        btn = QPushButton("ğŸ¤ ë…¹ìŒ ì‹œì‘")
        btn.clicked.connect(self._do_record)
        lay.addWidget(btn)

        self.setLayout(lay)

    def _do_record(self):
        self.record_func(self.path, self.duration)
        self.accept()

        

# ========== ë©”ì¸ UI ==========
class SmartDoorlockUI(QWidget):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("ğŸ” ìŠ¤ë§ˆíŠ¸ ë„ì–´ë½ ì‹œë®¬ë ˆì´í„°")
        self.setGeometry(1500, 0, 500, 1000)    # ì‹¤ì œ ì†Œí˜• LCD í™”ë©´ ë¹„ìœ¨ê³¼ ìœ ì‚¬í•˜ê²Œ
        self.setStyleSheet("background-color: white;")
        self.auth_fail_count = 0    # ì‹¤íŒ¨ íšŸìˆ˜ ì´ˆê¸°í™”
        self.second_attempts = 3    # 2ì°¨ ì¸ì¦ ì´ ì‹œë„ íšŸìˆ˜

        # â”€â”€ ë©”ì¸ ë ˆì´ì•„ì›ƒ (í•œ ë²ˆë§Œ!) â”€â”€
        main_lay = QVBoxLayout(self)
        main_lay.setContentsMargins(0,0,0,0)

        # â”€â”€ ì• ë‹ˆë©”ì´ì…˜ ë¼ë²¨ & ë…¹ìŒì¤‘ ë ˆì´ë¸” ì¤€ë¹„ â”€â”€
        self.label = QLabel(self)
        self.label.setFixedSize(500, 500)
        self.label.setAlignment(Qt.AlignCenter)
        self.movie = QMovie("gif/MainScene.gif")
        self.movie.setScaledSize(QSize(250, 250))
        self.label.setFixedHeight(500)
        # ìµœì´ˆì—” ì¬ìƒí•˜ì§€ ì•Šê³  ì²« í”„ë ˆì„ë§Œ
        self.movie.jumpToFrame(0)
        self.label.setPixmap(self.movie.currentPixmap())
        main_lay.addWidget(self.label)

        # â”€â”€ 2ì°¨ ì¸ì¦ ë¬¸ì¥ í‘œì‹œìš© ë ˆì´ë¸” â”€â”€
        self.challenge_label = QLabel("", self)
        self.challenge_label.setAlignment(Qt.AlignCenter)
        self.challenge_label.setStyleSheet("color: #bbbbbf; font-size: 23px;")
        self.challenge_label.setFixedHeight(100)
        self.challenge_label.hide()
        main_lay.addWidget(self.challenge_label)

        # â”€â”€ ë¯¸ë””ì–´ í”Œë ˆì´ì–´ ì¤€ë¹„ â”€â”€
        self.player = QMediaPlayer(self)

        # â”€â”€ ìƒíƒœ ë©”ì‹œì§€ ë ˆì´ë¸” ì¶”ê°€ â”€â”€
        self.status_label = QLabel("", self)
        self.status_label.setAlignment(Qt.AlignCenter)
        self.status_label.setStyleSheet("""
            color: #bbbbbf;
            font-size: 23px;
            padding: 8px;
        """)
        self.status_label.setFixedHeight(100)
        main_lay.addWidget(self.status_label)

        # â”€â”€ â€œë…¹ìŒì¤‘â€ í…ìŠ¤íŠ¸ ë ˆì´ë¸” â”€â”€
        self.recording_label = QLabel("ë…¹ìŒì¤‘â€¦", self)
        self.recording_label.setAlignment(Qt.AlignCenter)
        self.recording_label.setStyleSheet("color: #bbbbbf; font-size: 23px;")
        self.recording_label.setFixedHeight(60)
        self.recording_label.hide()               # ì´ˆê¸°ì—ëŠ” ìˆ¨ê¹€
        main_lay.addWidget(self.recording_label)

        # â”€â”€ ìœ„ì ¯ë“¤ ì‚¬ì´ì˜ ë‚¨ëŠ” ê³µê°„ì„ ì „ë¶€ ì°¨ì§€í•  ìŠ¤íŠ¸ë ˆì¹˜ ì¶”ê°€ â”€â”€
        main_lay.addStretch()

        # â”€â”€ ë²„íŠ¼ ë ˆì´ì•„ì›ƒ â”€â”€
        hbtn = QHBoxLayout()
        self.detect_btn = QPushButton("ğŸš¶ ì‚¬ìš©ì ì ‘ê·¼ ê°ì§€"); 
        self.detect_btn.clicked.connect(self.on_user_detected)
        self.detect_btn.setStyleSheet("""
            QPushButton {
                background-color: #3498db;
                color: white;
                border: none;
                padding: 8px 16px;
                border-radius: 4px;
            }
        """)
        self.create_btn = QPushButton("â• í”„ë¡œí•„ ìƒì„±");     
        self.create_btn.clicked.connect(self.create_profile)
        self.create_btn.setStyleSheet("""
            QPushButton {
                background-color: #3498db;
                color: white;
                border: none;
                padding: 8px 16px;
                border-radius: 4px;
            }
        """)
        hbtn.addWidget(self.detect_btn); hbtn.addWidget(self.create_btn)
        main_lay.addLayout(hbtn)

        self.profiles = []
        self.load_profiles()

    def show_animation(self):
        self.label.show()
        self.movie.start()
        
    def create_profile(self):
        name, ok = QInputDialog.getText(self, "í”„ë¡œí•„ ìƒì„±", "ì‚¬ìš©ì ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”:")
        if not ok or not name.strip():
            return
        name = name.strip()
        profile_dir = os.path.join(PROFILES_DIR, name)
        if os.path.exists(profile_dir):
            QMessageBox.warning(self, "ì¤‘ë³µ", "ì´ë¯¸ ì¡´ì¬í•˜ëŠ” í”„ë¡œí•„ì…ë‹ˆë‹¤.")
            return
        os.makedirs(profile_dir, exist_ok=True)

        sentences = [
            "ìŒì„±ìœ¼ë¡œ ë¬¸ì„ ì—´ê² ìŠµë‹ˆë‹¤. ì§€ê¸ˆë¶€í„° ì¸ì¦ì„ ì‹œì‘í•©ë‹ˆë‹¤.",
            "ì´ ë¬¸ì¥ì„ ì •í™•íˆ ë§í•˜ë©´ ì ê¸ˆì¥ì¹˜ê°€ í•´ì œë©ë‹ˆë‹¤.",
            "ì§€ê¸ˆ ë“¤ë¦¬ëŠ” ì´ ëª©ì†Œë¦¬ëŠ” ì €ë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë³´ì•ˆ ì—´ì‡ ì…ë‹ˆë‹¤.",
            "ìŠ¤ë§ˆíŠ¸ ë„ì–´ ì‹œìŠ¤í…œì„ í†µí•´ ì§‘ì— ì•ˆì „í•˜ê²Œ ë“¤ì–´ê°€ê³  ì‹¶ìŠµë‹ˆë‹¤.",
            "ì´ì œ ì œ ìŒì„±ìœ¼ë¡œ ë¬¸ì„ ì—´ ìˆ˜ ìˆëŠ” ì‹œëŒ€ê°€ ì™”ìŠµë‹ˆë‹¤. ì—´ì–´ì£¼ì„¸ìš”."
        ]

        ecapa_embs, wav_embs = [], []
        for i, sentence in enumerate(sentences):
            rec_path = os.path.join(profile_dir, f"rec{i+1}.wav")
            dialog = RecordingDialog(
                sentence,
                record_until_silence,
                rec_path,
                RECORD_DURATION
            )
            dialog.exec_()

            ecapa_embs.append(get_ecapa_embedding(rec_path).squeeze(0))
            wav_embs.append(get_wav2vec_pitch_embedding(rec_path).squeeze(0))

        # í‰ê·  ì„ë² ë”© ì €ì¥
        torch.save(torch.stack(ecapa_embs).mean(0), os.path.join(profile_dir, "ecapa.pt"))
        torch.save(torch.stack(wav_embs).mean(0),  os.path.join(profile_dir, "wav2vec.pt"))

        QMessageBox.information(self, "ì™„ë£Œ", "í”„ë¡œí•„ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        self.load_profiles()

    def load_profiles(self):
        self.profiles = [d for d in os.listdir(PROFILES_DIR)
                        if os.path.isdir(os.path.join(PROFILES_DIR, d))]
        
    def clear_status(self, delay=3000):
        """delay(ms) ë’¤ì— ë©”ì‹œì§€ ì§€ìš°ê¸°."""
        QTimer.singleShot(delay, lambda: self.status_label.setText(""))

    def on_user_detected(self):
        # 1) MP3 ì¬ìƒ â”€â”€
        mp3_path = os.path.abspath("mp3/Apple Intelligence Sound Effect.mp3")  # ì¬ìƒí•  íŒŒì¼ ê²½ë¡œ
        url = QUrl.fromLocalFile(mp3_path)
        media = QMediaContent(url)
        self.player.setMedia(media)
        self.player.play()

        # 2) ì‚¬ìš©ì ì ‘ê·¼ ê°ì§€ â†’ ì• ë‹ˆë©”ì´ì…˜ ì¬ìƒ + ë…¹ìŒì¤‘ í…ìŠ¤íŠ¸ ë³´ì´ê¸°
        self.label.setMovie(self.movie)
        self.movie.start()
        self.recording_label.setText("ë…¹ìŒì¤‘â€¦")
        self.recording_label.show()
        self.detect_btn.setEnabled(False)

        # 3) ì›Œì»¤ ìŠ¤ë ˆë“œë¡œ ë…¹ìŒ ì‹œì‘
        self.recorder = RecordWorker("login.wav", RECORD_SECONDS_LOGIN)
        self.recorder.finished.connect(self.on_record_finished)
        self.recorder.start()

    def on_record_finished(self, ok: bool):
        # ì´ ìŠ¬ë¡¯ì€ ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤.
        self.movie.stop()
        self.recording_label.hide()
        self.detect_btn.setEnabled(True)

        # ì›Œì»¤ ì‹¤í–‰
        self.auth_worker = AuthWorker(self.profiles)
        self.auth_worker.finished.connect(self.on_auth_done)
        self.auth_worker.start()

        if not ok:
            # ì˜¤ë¥˜ MP3 ì¬ìƒ
            mp3_path = os.path.abspath("mp3/Mac Error Sound Effect.mp3")  # ì¬ìƒí•  íŒŒì¼ ê²½ë¡œ
            url = QUrl.fromLocalFile(mp3_path)
            media = QMediaContent(url)
            self.player.setMedia(media)
            self.player.play()

            # ì˜¤ë¥˜ìš© GIF êµì²´
            error_movie = QMovie("gif/Error animation.gif")
            self.label.setMovie(error_movie)
            error_movie.setSpeed(75)# ê¸°ë³¸ ì†ë„ì˜ 75% â†’ ì ˆë°˜ ì†ë„ë¡œ ì¬ìƒ
            error_movie.start()

            self.status_label.setText("ì‹¤íŒ¨: ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            self.clear_status()
            return

        # ë…¹ìŒì´ ì„±ê³µí–ˆìœ¼ë‹ˆ 1ì°¨ ì¸ì¦ ë¡œì§ ì‹¤í–‰
        self.process_first_auth()

    def process_first_auth(self):
        if not self.profiles:
            # ì˜¤ë¥˜ MP3 ì¬ìƒ
            mp3_path = os.path.abspath("mp3/Mac Error Sound Effect.mp3")  # ì¬ìƒí•  íŒŒì¼ ê²½ë¡œ
            url = QUrl.fromLocalFile(mp3_path)
            media = QMediaContent(url)
            self.player.setMedia(media)
            self.player.play()

            # ì˜¤ë¥˜ìš© GIF êµì²´
            error_movie = QMovie("gif/Error animation.gif")
            self.label.setMovie(error_movie)
            error_movie.setSpeed(75)# ê¸°ë³¸ ì†ë„ì˜ 75% â†’ ì ˆë°˜ ì†ë„ë¡œ ì¬ìƒ
            error_movie.start()

            self.status_label.setText("ì˜¤ë¥˜: ë“±ë¡ëœ í”„ë¡œí•„ì´ ì—†ìŠµë‹ˆë‹¤.")
            self.clear_status()
            return

        # ë…¹ìŒ ëë‚¬ìœ¼ë‹ˆ â€œë…¹ìŒì¤‘â€ í…ìŠ¤íŠ¸ ìˆ¨ê¸°ê³  ì™„ë£Œ ì• ë‹ˆë©”ì´ì…˜ìœ¼ë¡œ êµì²´
        self.movie.stop()

        # 5ì´ˆ ë’¤ì— ë©”ì¸ í™”ë©´ìœ¼ë¡œ ë¦¬ì…‹
        #QTimer.singleShot(5000, self.reset_to_main_scene)

        if not self.profiles:
            # ì˜¤ë¥˜ MP3 ì¬ìƒ
            mp3_path = os.path.abspath("mp3/Mac Error Sound Effect.mp3")  # ì¬ìƒí•  íŒŒì¼ ê²½ë¡œ
            url = QUrl.fromLocalFile(mp3_path)
            media = QMediaContent(url)
            self.player.setMedia(media)
            self.player.play()

            # ì˜¤ë¥˜ìš© GIF êµì²´
            error_movie = QMovie("gif/Error animation.gif")
            self.label.setMovie(error_movie)
            error_movie.setSpeed(75)# ê¸°ë³¸ ì†ë„ì˜ 75% â†’ ì ˆë°˜ ì†ë„ë¡œ ì¬ìƒ
            error_movie.start()

            self.status_label.setText("ì˜¤ë¥˜: ë“±ë¡ëœ í”„ë¡œí•„ì´ ì—†ìŠµë‹ˆë‹¤.")
            self.clear_status()
            return

        best_match, best_score = None, 0.0

        print("1ì°¨ ì¸ì¦ ê²°ê³¼")
        for p in self.profiles:
            profile_dir = os.path.join(PROFILES_DIR, p)
            # 1) ë‚´ë¶€ ìœ ì‚¬ë„ ë¡œê·¸
            combined = compare_with_ensemble(profile_dir, "login.wav")
            # 2) í”„ë¡œí•„ë³„ ìµœì¢… ìœ ì‚¬ë„ ë¡œê·¸
            print(f"[ìœ ì‚¬ë„] {p}: {combined:.4f}")

            if combined > best_score:
                best_score = combined
                best_match = p

        if best_score >= SIMILARITY_THRESHOLD:
            error_movie = QMovie("gif/Success.gif")
            self.label.setMovie(error_movie)
            error_movie.setSpeed(75)# ê¸°ë³¸ ì†ë„ì˜ 75% â†’ ì ˆë°˜ ì†ë„ë¡œ ì¬ìƒ
            error_movie.start()
            self.status_label.setText(f"1ì°¨ ì¸ì¦ ì„±ê³µ: {best_match}ë‹˜, ì•ˆë…•í•˜ì„¸ìš”!")
            self.start_second_auth(best_match)
        else:
            # ì˜¤ë¥˜ MP3 ì¬ìƒ
            mp3_path = os.path.abspath("mp3/Mac Error Sound Effect.mp3")  # ì¬ìƒí•  íŒŒì¼ ê²½ë¡œ
            url = QUrl.fromLocalFile(mp3_path)
            media = QMediaContent(url)
            self.player.setMedia(media)
            self.player.play()

            # ì˜¤ë¥˜ìš© GIF êµì²´
            error_movie = QMovie("gif/Error animation.gif")
            self.label.setMovie(error_movie)
            error_movie.setSpeed(75)# ê¸°ë³¸ ì†ë„ì˜ 75% â†’ ì ˆë°˜ ì†ë„ë¡œ ì¬ìƒ
            error_movie.start()

            self.status_label.setText("ì¸ì¦ ì‹¤íŒ¨: ë“±ë¡ë˜ì§€ ì•Šì€ ìŒì„±ì…ë‹ˆë‹¤.")
        self.clear_status()

    def start_second_auth(self, user):
        # 1) ëœë¤ ë¬¸ì¥ ì„ íƒ
        sentence = random.choice([
            "ì„œìš¸ì˜ ì¤‘ì‹¬ì€ ê´‘í™”ë¬¸ì…ë‹ˆë‹¤.",
            "ì˜¤ëŠ˜ë„ ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”.",
            "ë´„ì—ëŠ” ê½ƒì´ í”¼ê³  ìƒˆê°€ ë‚ ì•„ìš”."
        ])
        # 2) í™”ë©´ì— ë³´ì—¬ì£¼ê¸°
        self.challenge_label.setText(f"2ì°¨ ì¸ì¦\n\nã€Œ{sentence}ã€")
        self.challenge_label.show()

        # 3) ì• ë‹ˆë©”ì´ì…˜ ì¬ìƒ
        auth_movie = QMovie("gif/Find people.gif")
        self.label.setMovie(auth_movie)
        auth_movie.setSpeed(75)# ê¸°ë³¸ ì†ë„ì˜ 75% â†’ ì ˆë°˜ ì†ë„ë¡œ ì¬ìƒ
        auth_movie.start()

        # 4) ë²„íŠ¼ ì ê¸ˆ
        self.detect_btn.setEnabled(False)

        # 5) ì›Œì»¤ì— sentenceë„ ë„˜ê¸°ê¸°
        self.second_worker = SecondAuthWorker(
            user=user,
            sentence=sentence,
            attempts=self.second_attempts
        )
        self.second_worker.finished.connect(self.on_second_auth_finished)
        self.second_worker.start()

    def on_auth_done(self, success: bool, message: str):
        # ì›Œì»¤ê°€ ëë‚˜ë©´ í˜¸ì¶œ â€” UIëŠ” ê³„ì† ëŒì•„ê°€ê³  ìˆìŠµë‹ˆë‹¤
        self.status_label.setText(message)
        self.clear_status()

    def on_second_auth_finished(self, success, message):
        # ì±Œë¦°ì§€ ë¬¸ì¥ ìˆ¨ê¸°ê¸°
        self.challenge_label.hide()
        # ê¸°ì¡´ ì„±ê³µ/ì‹¤íŒ¨ ì²˜ë¦¬â€¦
        movie = QMovie("gif/Success.gif" if success else "gif/Error animation.gif")
        self.label.setMovie(movie)
        movie.start()
        self.status_label.setText(message)
        self.clear_status()
        self.detect_btn.setEnabled(True)
        if not success:
            self.second_attempts -= 1
            return
        
        # ì„±ê³µì¼ ë•Œë§Œ 5ì´ˆ ë’¤ì— ë©”ì¸ í™”ë©´ìœ¼ë¡œ ë¦¬ì…‹
        QTimer.singleShot(5000, self.reset_to_main_scene)

    def reset_to_main_scene(self):
        # MainScene.gifì˜ ì²« í”„ë ˆì„ì„ ë„ìš´ ì±„ ì •ì§€
        main_movie = QMovie("gif/MainScene.gif")
        main_movie.setScaledSize(QSize(250, 250))
        main_movie.jumpToFrame(0)
        # QMovieê°ì²´ê°€ ì•„ë‹Œ í˜„ì¬ í”„ë ˆì„ë§Œ í‘œì‹œí•˜ë ¤ë©´ setPixmap
        self.label.setPixmap(main_movie.currentPixmap())
        # ë‹¤ìŒë²ˆ ì¬ìƒì„ ìœ„í•´ self.movieì—ë„ ì €ì¥
        self.movie = main_movie

    def unlock_door(self, user):
        self.status_label.setText(f"{user}ë‹˜ í™˜ì˜í•©ë‹ˆë‹¤! ë¬¸ì´ ì—´ë ¸ìŠµë‹ˆë‹¤.")
        self.clear_status(delay=10000)
        
    def show_emergency_ui(self):
        pwd, ok = QInputDialog.getText(self, "ë¹„ìƒ ì¶œì…", "ë¹„ë°€ë²ˆí˜¸ ì…ë ¥:")
        if ok and pwd == "1234":
            QMessageBox.information(self, "ë¹„ìƒ í†µê³¼", "ë¬¸ì´ ì—´ë ¸ìŠµë‹ˆë‹¤.")
            self.auth_fail_count = 0
        else:
            QMessageBox.critical(self, "ì‹¤íŒ¨", "ë¹„ìƒ ì¸ì¦ ì‹¤íŒ¨")

if __name__ == "__main__":
    app = QApplication(sys.argv)
    w = SmartDoorlockUI()
    w.show()
    sys.exit(app.exec_())
